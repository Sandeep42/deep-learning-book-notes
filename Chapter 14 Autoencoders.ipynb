{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder is a neural network that is trained to attempt to copy its input to output. If it copies input to output perfectly, it is not learning any useful representation. Usually, we want to learn a representation that is good to do some other task, this notion of good representation is not going to be defined for us. We use an encoder to learn a latent representation of input, and the decoder is learned to reproduce the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undercomplete Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hidden dimension less than input dimension\n",
    "* If the encoder and decoder are given too many parameters to play with, they would not learn anything useful and perfectly copy the input data. \n",
    "* Like all neural networks, we minimize\n",
    "\n",
    "$$ L(x,g(f(x))) $$\n",
    "* Here L is some function which measure how close input is to the output, something like Mean squared error.\n",
    "* If the decoder is linear and loss function is MSE, then this setup reduces to a PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Give the autoencoder more than enough capacity to copy itself, but regualarize it hard. This could potentially solve all the problems occuring with overcomplete autoencoders, you can still learn an useful representation even if you don't know the optimal latent dimenstion.\n",
    "* Looks like there are two routes to getting generative models, one is learning autoencoder or autoencoder like network that can learn to map the input into a latent space. The other route is directly optimize probability of seeing training data rather than learning to copy it.\n",
    "* Variational autoencoder, Helmholtz machine take the second route.\n",
    "* What is an useful representation? How do you even go about training a generative model in high dimensions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sparse autoencoder is an autoencoder with regularization (book calls it sparse penalty), you are essentially adding more cost to the optimizer so that the solutions become sparse.\n",
    "* A common thing throughout deep learning saga: ** Add more randomness to the model, be it noise, regularization, more filters, pooling. It always tends to improve the performance of the model. It is as if mother nature rewards you for being uncertain about a certain thing rather than being certain.**. I don't know why exactly this happens, but that has been the mantra to make these models work. My intution says it has to do with sampling especially Monte Carlo like methods. They use random numbers to estimate the distribution and this is also similar.\n",
    "* Coming to sparse AE, why sparsity is needed? You would want to do some other task like classification using this representation, and adding sparse regularizer would improve the performance because you are asking it forget most of the variables necessary to copy itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
