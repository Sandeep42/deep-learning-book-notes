{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "A learned model has to perform well not only on training data, but also on unseen data. To ensure that the model did not overfit and generalize well, regularization is a prominently used method. To put it bluntly, regularization is any additional parameters or noise added to the learning model so as to make it more robust and general. \n",
    "\n",
    "Typically, regularization is a penalty added to the parameter space. Adding an extra term to the loss function puts an additional constraint on the optimization objective. Regularization is generally not applied to the bias term.\n",
    "\n",
    "$$ \\widetilde J(\\theta; X,y) = J(\\theta; X,y) + \\alpha * W(\\theta) $$\n",
    "\n",
    "In deep learning, is is quite common to use different $ \\alpha $ to different layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 7.1. $ L^2$ (Ridge) Regularization \n",
    "\n",
    "* The cost function for Ridge:\n",
    "\n",
    "$$ \\widetilde J(W; X,y) = J(W; X,y) + 0.5 * \\alpha * W^T W $$\n",
    "\n",
    "$$ \\nabla_W  \\widetilde J(\\theta; X,y) = \\alpha * W + \\nabla_W  J(W; X,y) $$\n",
    "\n",
    "* A single step of weight updates would need\n",
    "\n",
    "$$ W \\leftarrow W - \\epsilon  ( \\alpha * W + \\nabla_W  J(W; X,y) ) $$\n",
    "\n",
    "$$ W \\leftarrow (1- \\epsilon \\alpha) W + \\epsilon \\nabla_W  J(W; X,y) $$\n",
    "\n",
    "\n",
    "* This shrinks the weights by an extra constant factor. To get a intuition for what this extra tem is doing, Ian Goodfellow follows an elaborate path considering quadratic approximation of the loss function, and allows us to look at how eigenvalues of Hessian matrix effect the parameters W. I think this approximation is a beautiful thing to look at, so we will have to dig a little bit more into the math."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "* ** Note-1: ** Jacobian and Hessian matrices are generalization of differential calculus to multivariate functions.\n",
    "\n",
    " Jacobian $ \\rightarrow $ All the first order derivatives of a function whose input and output are both vectors or      simply the gradient\n",
    "\n",
    " Hessian $ \\rightarrow $  All the second order derivatives of a function whose input and output are both vectors or simply rate of change of gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* ** Note-2: ** Quadratic approximation of a function with Hessian matrix\n",
    "\n",
    " This is kind of like Taylor expansion for multivariate functions. Quadratic approximation can be deduced as-\n",
    " \n",
    " where $H_f(x_0)$ is the Hessian at point $ x_0 $ \n",
    "\n",
    "$$ Q_f(x,y) = f(x_0) + \\nabla f(x_0)(x-x_0) + 0.5 * \\nabla (x-x_0)^T H_f(x_0) (x-x_0)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Considering the quadratic approximation to cost function gives\n",
    "\n",
    " where $ W^* $ is the point at which the gradient vanishes\n",
    "\n",
    "$$ \\widetilde J(W) = J(W^*) + 0.5 * (W-W^*)^T H (W-W^*) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* To mimimize $ J(W) \\rightarrow H(W-W^*) = 0 $\n",
    "\n",
    "* When regularization is added and quadratic approximation is used\n",
    "\n",
    "$$ \\alpha \\widetilde W + H(\\widetilde W - W^*) = 0 $$\n",
    "\n",
    "$$ \\widetilde W = (H+ \\alpha I)^{-1} H W^* $$\n",
    "\n",
    "* So regularization actually changes the behavior of parameter space. \n",
    "\n",
    "* When $\\alpha \\rightarrow$ 0 the weight matrix approaches local minima. When $\\alpha$ increases, using SVD of Hessian, where D is the diagonal matrix, and Q are the eigenvectors,\n",
    "\n",
    "$$ \\widetilde W = (QDQ^T + \\alpha I)^{-1} QDQ^T W^* $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Raising alpha with rescale the parameters along axis defined by eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "* ** Keypoint: ** Only the directions in which the parameters have contribution towards the minimization of objective function are preserved. In the other directions, eigenvalue of Hessian is not really significany and they are decayed. This sort of regularizes the unimportant variables in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Example of Regularization on Linear Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Cost function of linear regression without regularization.\n",
    "\n",
    "$$ J(W) = {(XW- Y)}^T(XW- Y) $$\n",
    "\n",
    "* With regularization \n",
    "\n",
    "$$ \\widetilde J(W) = {(XW- Y)}^T(XW- Y) + 0.5 * \\alpha * W^T W $$\n",
    "\n",
    "$$  W = {(X^TX + \\alpha I)}^{-1} X^TY $$\n",
    "\n",
    "* Here $ X^TX $ is the covariance matrix, so an additional $\\alpha$ is added to it.\n",
    "* This makes the learning algorithm perceive X as having higher variance in one direction rather than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## $L^1$ Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "* $ L^1 $ regularization is just the sum of absolute values of parameters.\n",
    "\n",
    "  $$ \\lambda(\\theta) = | W |$$\n",
    "\n",
    "* The derivate of loss with respect to the weights becomes \n",
    "\n",
    "  $$  \\nabla_W \\widetilde J(W;X,Y) = \\alpha |W| + \\nabla_W J(W;X,Y) $$\n",
    "  \n",
    "\n",
    "* When you use this loss function in the optimization objective, it tends to make things either go to zero or it makes a shift in the parameters. The book goes into a little depth about this, I could not properly understand it.\n",
    "\n",
    "* This forces the optimizer to choose sparse solutions, hence $L^1$ is used as a feature selection method.\n",
    "\n",
    "* ** Some trivia: ** $L^2$ regularization can be seen as Bayesian inference with a Gaussian prior and $L^1$ also has a similar intrepretation of prior. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 7.2. Norm Penalties as Constained Optimization \n",
    "\n",
    "Should have read the fourth chapter first, my non-linear style reading made sure that I can't understand a thing out of this section. TO DO later!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 7.3. Regularization and under-constrained problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
